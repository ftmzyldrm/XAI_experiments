{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CEM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WvCxPMEhaJz",
        "outputId": "4de0b5eb-dee0-4b68-8c98-d59124810796"
      },
      "source": [
        "# @title Install Alibi\n",
        "try:\n",
        "  import alibi\n",
        "except:\n",
        "  !pip install alibi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting alibi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/c1/7e6bbb4a69d84063d84dbf39ef5f95d9ee230379c542bed4e44ca8b878d8/alibi-0.5.5-py3-none-any.whl (228kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 15.5MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20kB 9.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 30kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 40kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 51kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 81kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 102kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 112kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 122kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 133kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 143kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 153kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 163kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 174kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 184kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 194kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 204kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 215kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 225kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from alibi) (0.22.2.post1)\n",
            "Requirement already satisfied: spacy[lookups] in /usr/local/lib/python3.6/dist-packages (from alibi) (2.2.4)\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.6/dist-packages (from alibi) (2.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from alibi) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from alibi) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from alibi) (1.1.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.2 in /usr/local/lib/python3.6/dist-packages (from alibi) (3.7.4.3)\n",
            "Requirement already satisfied: scikit-image!=0.17.1 in /usr/local/lib/python3.6/dist-packages (from alibi) (0.16.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from alibi) (20.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from alibi) (3.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from alibi) (2.23.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from alibi) (7.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from alibi) (4.6.3)\n",
            "Collecting shap>=0.36\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/a3/c0eab9dd6a894165e2cb87504ff5b2710ac5ede3447d9138620b7341b6a2/shap-0.37.0.tar.gz (326kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->alibi) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (51.1.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[lookups]->alibi) (0.8.0)\n",
            "Collecting spacy-lookups-data<0.2.0,>=0.0.5; extra == \"lookups\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/4a37ca7d0c21dc2287a8bb5d249f5f3211cdf3d598acf742bf5bb8c87169/spacy_lookups_data-0.1.0.tar.gz (28.0MB)\n",
            "\u001b[K     |████████████████████████████████| 28.0MB 144kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (2.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (0.10.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (0.36.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (2.4.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (0.3.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.6.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.32.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (3.12.4)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.12)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->alibi) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->alibi) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->alibi) (2018.9)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image!=0.17.1->alibi) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image!=0.17.1->alibi) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image!=0.17.1->alibi) (2.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->alibi) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->alibi) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->alibi) (0.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->alibi) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->alibi) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->alibi) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->alibi) (3.0.4)\n",
            "Collecting slicer==0.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/02/a6/c708c5a0f338e99cfbcb6288b88794525548e4fc1b8457feec2c552a81a4/slicer-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from shap>=0.36->alibi) (0.48.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy[lookups]->alibi) (3.3.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.0->alibi) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.0->alibi) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.0->alibi) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.0->alibi) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.0->alibi) (1.17.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image!=0.17.1->alibi) (4.4.2)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->shap>=0.36->alibi) (0.31.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy[lookups]->alibi) (3.4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.0->alibi) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0->alibi) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0->alibi) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0->alibi) (4.2.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.0->alibi) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0->alibi) (0.4.8)\n",
            "Building wheels for collected packages: shap, spacy-lookups-data\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.37.0-cp36-cp36m-linux_x86_64.whl size=463904 sha256=2a635b3917a1dd1e98754990b18397adac722d0795dbaeb5608c49fa5a2c09c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/ad/b0/aa7815ec68850d66551ef618095eccb962c8f6022f1d3dd989\n",
            "  Building wheel for spacy-lookups-data (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spacy-lookups-data: filename=spacy_lookups_data-0.1.0-py2.py3-none-any.whl size=28052145 sha256=a1866d0ef52e2b9b16d843eec97f02cc5adbc5e013e8fae2109986257e6bc2ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/2b/0a/d6fb6235c56d014d224bca760d15d7cbdd820813085ffcd35d\n",
            "Successfully built shap spacy-lookups-data\n",
            "Installing collected packages: slicer, shap, alibi, spacy-lookups-data\n",
            "Successfully installed alibi-0.5.5 shap-0.37.0 slicer-0.0.3 spacy-lookups-data-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "i9_LKFgWiSmz"
      },
      "source": [
        "# @title Import Modules\n",
        "import tensorflow as tf\n",
        "#tf.logging.set_verbosity(tf.logging.ERROR) # suppress\n",
        "                                           # deprecation messages\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Conv2D,Dense, Dropout, Flatten, MaxPooling2D,Input,UpSampling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "import os\n",
        "from time import time\n",
        "from alibi.explainers import CEM"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "cellView": "code",
        "id": "aKPpS3iHjyVS",
        "outputId": "d72e1258-47fd-4302-af07-b1cc8e1f485a"
      },
      "source": [
        "# @title Load and prepare MNIST data\n",
        "(x_train, y_train),(x_test,y_test) =tf.keras.datasets.mnist.load_data()\n",
        "print('x_train shape:', x_train.shape, 'y_train shape:',\n",
        "      y_train.shape)\n",
        "plt.gray()\n",
        "plt.imshow(x_test[15]);\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "code",
        "id": "cI_2pJIlpXrs",
        "outputId": "280eea40-a409-40f5-c930-32adc430bdd0"
      },
      "source": [
        "# @title Preparing data: scaling the data\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "print(x_test[1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.45490196 0.49019608\n",
            "  0.67058825 1.         1.         0.5882353  0.3647059  0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.6627451  0.99215686 0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.99215686 0.85490197 0.11764706\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.6627451  0.99215686 0.99215686 0.99215686\n",
            "  0.8352941  0.5568628  0.6901961  0.99215686 0.99215686 0.47843137\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.20392157 0.98039216 0.99215686 0.8235294  0.1254902\n",
            "  0.04705882 0.         0.02352941 0.80784315 0.99215686 0.54901963\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.3019608  0.9843137  0.8235294  0.09803922 0.\n",
            "  0.         0.         0.47843137 0.972549   0.99215686 0.25490198\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.12156863 0.07058824 0.         0.\n",
            "  0.         0.         0.81960785 0.99215686 0.99215686 0.25490198\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.45882353 0.96862745 0.99215686 0.7764706  0.03921569\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.29803923 0.96862745 0.99215686 0.90588236 0.24705882 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.5019608  0.99215686 0.99215686 0.5647059  0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.6901961\n",
            "  0.9647059  0.99215686 0.62352943 0.04705882 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.09803922 0.91764706\n",
            "  0.99215686 0.9137255  0.13725491 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.7764706  0.99215686\n",
            "  0.99215686 0.5529412  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.30588236 0.972549   0.99215686\n",
            "  0.7411765  0.04705882 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.07450981 0.78431374 0.99215686 0.99215686\n",
            "  0.5529412  0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.5254902  0.99215686 0.99215686 0.6784314\n",
            "  0.04705882 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.972549   0.99215686 0.99215686 0.09803922\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.972549   0.99215686 0.99215686 0.16862746\n",
            "  0.07843138 0.07843138 0.07843138 0.07843138 0.01960784 0.\n",
            "  0.01960784 0.07843138 0.07843138 0.14509805 0.5882353  0.5882353\n",
            "  0.5882353  0.5764706  0.03921569 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.972549   0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.99215686 0.65882355 0.56078434\n",
            "  0.6509804  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.99215686 0.48235294 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.68235296 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.99215686 0.9764706  0.96862745 0.96862745 0.6627451\n",
            "  0.45882353 0.45882353 0.22352941 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.4627451  0.48235294 0.48235294\n",
            "  0.48235294 0.6509804  0.99215686 0.99215686 0.99215686 0.60784316\n",
            "  0.48235294 0.48235294 0.16078432 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzXNLacjpjFc",
        "outputId": "f4de340b-1af3-4ee4-ff70-27fc13a11edd"
      },
      "source": [
        "# @title Preparing data: shaping the data\n",
        "print(\"Initial Shape\", x_test.shape)\n",
        "x_train = np.reshape(x_train, x_train.shape + (1,))\n",
        "x_test = np.reshape(x_test, x_test.shape + (1,))\n",
        "print('x_train shape:', x_train.shape, 'x_test shape:', x_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Shape (10000, 28, 28)\n",
            "x_train shape: (60000, 28, 28, 1) x_test shape: (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIf2xuSHpsSX",
        "outputId": "a7fdd3dc-6173-4ce8-a6ea-b83c2bbf583a"
      },
      "source": [
        "# @title Preparing data: categorizing the data\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "print('y_train shape:', y_train.shape, 'y_test shape:', y_test.shape)\n",
        "xmin, xmax = -.5, .5\n",
        "x_train = ((x_train - x_train.min()) /\n",
        "    (x_train.max() - x_train.min())) * (xmax - xmin) + xmin\n",
        "x_test = ((x_test - x_test.min()) / (x_test.max() - x_test.min())) * (xmax - xmin) + xmin\n",
        "\n",
        " "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train shape: (60000, 10) y_test shape: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "-n_8oGusp9_g"
      },
      "source": [
        "# @title Create and train CNN model\n",
        "def cnn_model():\n",
        "    x_in = Input(shape=(28, 28, 1))\n",
        "    x = Conv2D(filters=64, kernel_size=2, padding='same',\n",
        "               activation='relu')(x_in)\n",
        "    x = MaxPooling2D(pool_size=2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Conv2D(filters=32, kernel_size=2, padding='same',\n",
        "               activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x_out = Dense(10, activation='softmax')(x)\n",
        "    cnn = Model(inputs=x_in, outputs=x_out)\n",
        "    cnn.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "    return cnn\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tes4lHtoqaIo",
        "outputId": "4509e569-ab3b-481d-e4ad-f58850be1ba5"
      },
      "source": [
        "train_cnn = 'yes' # @param [\"yes\",\"no\"]\n",
        "if train_cnn == \"yes\":\n",
        "  cnn = cnn_model()\n",
        "  cnn.summary()\n",
        "  cnn.fit(x_train, y_train, batch_size=64, epochs=3, verbose=0)\n",
        "  cnn.save('mnist_cnn.h5')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 64)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 32)        8224      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               401664    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 412,778\n",
            "Trainable params: 412,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "code",
        "id": "Y8skSH2ZqsRL",
        "outputId": "826502ea-614c-40fd-dcf3-f5bf538c9287"
      },
      "source": [
        "# @title Load and test accuracy on test dataset\n",
        "cnn = load_model('/content/mnist_cnn.h5')\n",
        "cnn.summary()\n",
        "score = cnn.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuracy: ', score[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 64)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 32)        8224      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               401664    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 412,778\n",
            "Trainable params: 412,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test accuracy:  0.9872999787330627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "cGVSMJOirHNd"
      },
      "source": [
        "# @title Define and train autoencoder\n",
        "def ae_model():\n",
        "    x_in = Input(shape=(28, 28, 1))\n",
        "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x_in)\n",
        "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    encoded = Conv2D(1, (3, 3), activation=None, padding='same')(x)\n",
        "    x = Conv2D(16, (3, 3), activation='relu',\n",
        "               padding='same')(encoded)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "    decoded = Conv2D(1, (3, 3), activation=None, padding='same')(x)\n",
        "    autoencoder = Model(x_in, decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "    \n",
        "    return autoencoder"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wszuvmRdywpT"
      },
      "source": [
        "train_auto_encoder = 'yes' # @param [\"yes\",\"no\"]\n",
        "if train_auto_encoder == \"yes\":\n",
        "  ae = ae_model()\n",
        "  # ae.summary()\n",
        "  ae.fit(x_train, x_train, batch_size=128, epochs=4,\n",
        "         validation_data=(x_test, x_test), verbose=0)\n",
        "  ae.save('mnist_ae.h5', save_format='h5')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPSO0rvWzTsd",
        "outputId": "f9dd962d-7415-4263-8fcb-643c516de15d"
      },
      "source": [
        "# @title Compare original with decoded images\n",
        "ae = load_model('/content/mnist_ae.h5')\n",
        "ae.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 1)         145       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 16)        160       \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 16)        2320      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 1)         145       \n",
            "=================================================================\n",
            "Total params: 5,250\n",
            "Trainable params: 5,250\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KU6jRjIzZhC"
      },
      "source": [
        "decoded_imgs = ae.predict(x_test)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "HL6uX5eIzinU",
        "outputId": "882c85be-2ca6-4cf1-9f3d-62ea9224e407"
      },
      "source": [
        "n = 5\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(1, n+1):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABBAAAADrCAYAAADQf2U5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZBVxfXA8R5k37dRFpVFAgYB2TVEiRJKFBlQBCSoMZhySeKS0qClxPhzt0jEooJCtOIecQElqLgH3EJUiIjIYsAAYhmZAWZkWBSY9/vjV7/O6SO3+97Le2/eDN/PX+dWv/duD95+fd+1T5+iTCZjAAAAAAAAfOpUdwcAAAAAAEDh4wECAAAAAAAI4gECAAAAAAAI4gECAAAAAAAI4gECAAAAAAAI4gECAAAAAAAIqpvkxUVFRdR8LBxlmUymuLo7gcLA2CwcmUymqLr7gMLAuCwozJmwGJsFhbEJi7FZUCLHJisQaq6N1d0BAABqCOZMoDAxNoHCFDk2eYAAAAAAAACCeIAAAAAAAACCeIAAAAAAAACCeIAAAAAAAACCeIAAAAAAAACCeIAAAAAAAACCeIAAAAAAAACCeIAAAAAAAACCeIAAAAAAAACC6lZ3B9L6zW9+4xw3atTIxn369HHaxo0bF/k5s2bNco6XLFli48cee+xguggAAAAAQK3BCgQAAAAAABDEAwQAAAAAABBUo1IYnnrqKRv70hK0qqqqyLZLL73UOR4+fLiN33zzTadt06ZNsc8JILu6d+9u4zVr1jhtV111lY3/+Mc/5q1PQG3QpEkT5/j3v/+9jfUcuWzZMud4/PjxNt64cWMOegcAAAoJKxAAAAAAAEAQDxAAAAAAAEAQDxAAAAAAAEBQQe+BIPc8MCb+vgc6P/qVV16xcdeuXZ22kpIS5/iYY46x8Xnnnee03XnnnbHODyD7+vXrZ2O9r8nmzZvz3R2g1mjfvr1zfPHFF9tYj7UBAwY4x6NGjbLxvffem4PeAbVb//79neNnn33Wxp07d875+U877TTnePXq1Tb+/PPPc35+4FAjf3suWLDAabv88sttPHv2bKdt//79ue1YAqxAAAAAAAAAQTxAAAAAAAAAQQWXwjBw4EAbn3322ZGv++STT5zj0aNH27isrMxpq6ystHH9+vWdtn/84x/O8fHHH2/jNm3axOgxgHzo27evjXfu3Om0Pffcc/nuDlCjFRcX2/iRRx6pxp4Ah7YRI0Y4xw0aNMjr+XUq70UXXWTjiRMn5rUvQG2kf0/ed999ka+dOXOmjR988EGnbffu3dnt2EFgBQIAAAAAAAjiAQIAAAAAAAjiAQIAAAAAAAgquD0QZDmpoqIip03ue6Bzxr788stYn3/NNdc4xz179ox87YsvvhjrMwFkX69evZxjWdrmsccey3d3gBrtyiuvdI7POussGw8ePDj15w4dOtTGdeq4/0/io48+svFbb72V+hxAbVO37n9vv0eOHFmNPTFm2bJlzvHVV19t4yZNmjhtev8hAGFynjTGmCOPPDLytXPmzLHxnj17ctang8UKBAAAAAAAEMQDBAAAAAAAEFRwKQzPP/+8jbt16+a07dixw8bbtm1L9fm6JE29evVSfQ6A3Dr22GOdY7mU8qmnnsp3d4Aa7Z577nGOq6qqsvK5Y8eOPWBsjDEbN2608bnnnuu06WXTwKHk1FNPtfEPfvADp23atGl57UurVq2cY5na27hxY6eNFAYgTJdinTp1auz3yhTdTCaTtT5lGysQAAAAAABAEA8QAAAAAABAEA8QAAAAAABAUMHtgSDJ/MmDMWXKFBt3797d+9r33nvvgDGA/Lr22mudY/l9sHTp0nx3B6hxFi5caGNdYjGtrVu3OseVlZU27tSpk9PWpUsXG7///vtO22GHHZaV/gA1gS5LLEu1rV+/3mm744478tKn/zdmzJi8ng+o7Xr37u0cDxgwIPK1+/btc45feumlnPQp21iBAAAAAAAAgniAAAAAAAAAggo6hSGtUaNGOce33HKLjevXr++0bdmyxTm+/vrrbbxr164c9A7AgXTu3Nk5HjhwoHP86aef2phSUsB3/ehHP3KOe/ToYWNdtjFuGcfZs2c7x6+++qpzXFFRYeNhw4Y5bb7SVb/4xS9sPGvWrFh9AWqq3/72t86xLEt8+umnO20yLShXWrdubWP9vZGtEq/Aoeqcc86J/Vo9p9YUrEAAAAAAAABBPEAAAAAAAABBPEAAAAAAAABBtXIPBJ07rfc9kJ566inn+M0338xJnwD46TxMrbS0NE89AWoOuXfIk08+6bS1bds21mfoksnz5s2z8c033+y0+fYG0p9zySWX2Li4uNhpmzZtmo0bNmzotM2cOdPGe/fujTwfUMjGjRtn45EjRzpt69ats3F1lCWW+5PoPQ8WL15s4/Ly8nx1Cag1hg4d6m3/9ttvbezbK6iQsQIBAAAAAAAE8QABAAAAAAAE1ZoUhvnz59v4tNNOi3zdo48+6hzr0joAqkfv3r297XLJM4D/U7fuf6fxuCkLxrjpehMnTnTaysrKUvVFpzDceeedNp4+fbrT1rhxYxvrsb1gwQIbr1+/PlVfgOo2fvx4G8vr3Rhj7rvvvrz2RZdJPu+882y8f/9+p+22226zMSlEQDxDhgw5YHwgshT58uXLc9anXGIFAgAAAAAACOIBAgAAAAAACOIBAgAAAAAACKqxeyC0b9/eOZb5Jg0aNHDaZD6nzO0yxpjKysoc9A5AHCeeeKKNJ0+e7LR9+OGHzvFrr72Wlz4BtZEuFXfRRRfZOO2eByFyLwOZc22MMYMGDcrJOYHq0qJFC+dYzm/arFmzct0dhyypaoy7X8rq1audtkWLFuWlT0BtkmROy/f4zwVWIAAAAAAAgCAeIAAAAAAAgKAam8Iwb94857hNmzaRr3388cdtTEkooHAMHz7cxq1bt3baXn75Zed4z549eekTUFPVqRP9/wROOOGEPPbk/xQVFdlY983X1//5n/+x8QUXXJD1fgG5oNNnO3bsaOM5c+bkuzuOY445JrJt5cqVeewJUDsNHDgwsq28vNw5JoUBAAAAAAAcEniAAAAAAAAAgniAAAAAAAAAgmrUHgijR4+2cf/+/SNft3jxYuf4pptuylWXAByE448/3saZTMZpmzt3br67A9Q4l112mY2rqqqqsSffVVJSYuN+/fo5bbKvut9yDwSgptixY4dzvHz5chv36dPHaZN7/mzbti0n/Tn88MNtPG7cuMjXvfPOOzk5P1CbnXTSSc7xpEmTIl9bUVHhHG/evDknfconViAAAAAAAIAgHiAAAAAAAIAgHiAAAAAAAICggt4DoU2bNs7xDTfcYON69epFvk/mnRljTGVlZXY7BiCVdu3aOccnn3yyjdeuXeu0Pffcc3npE1CTyX0GqkNxcbGNe/bs6bTJOduntLTUOd67d+/BdwzIs927dzvH69evt/E555zjtL344os2nj59eqrz9erVyznu2rWrc9y5c2cb6z2GpELbOwWoCfRv1Dp1ov+f/GuvvZbr7uQdKxAAAAAAAEAQDxAAAAAAAEBQQacwXHPNNc7xoEGDIl87f/58G1O2EShMP/vZz5xjWWbqpZdeynNvABysqVOn2vhXv/pV7Pdt2LDBxhdeeKHTtmnTpoPuF1Dd5L1oUVGR03bmmWfaeM6cOak+v6yszDnWaQpt27aN9TkPP/xwqvMDhzJfadTy8nLn+E9/+lOuu5N3rEAAAAAAAABBPEAAAAAAAABBPEAAAAAAAABBBb0HwtVXXx37tZdffrmNKdsIFKZOnTpFtm3fvj2PPQGQxsKFC53jHj16pPqcVatW2fidd945qD4BhWjNmjU2njBhgtPWt29fG3fr1i3V58+dO9fb/sgjj9j4vPPOi3ydLj8J4MCOPPJIG0+aNCnydZs3b3aOly5dmrM+VRdWIAAAAAAAgCAeIAAAAAAAgKCCTmFIonXr1jbeu3dv6s+pqKiI/Jx69erZuEWLFpGf0bJlS+c4birG/v37nePrrrvOxrt27Yr1GUAhGzVqVGTb888/n8eeALWDLA9Xp070/xM444wzItvuv/9+57hDhw6Rr9XnqKqqCnXxgEpKSlK9D6gNli9ffsA4mz777LNYr+vVq5dzvHLlylx0B6jxhgwZYmPffDt//vx8dKdasQIBAAAAAAAE8QABAAAAAAAE8QABAAAAAAAE1Zo9EFasWJGVz3nmmWds/OWXXzptRxxxhI3PPffcrJzP5z//+Y+Nb7/99pyfD8iFk046ycbt2rWrxp4Atc+sWbNsPG3atMjXvfDCC86xb++CJPsaxH3t7NmzY38mgIMn90eRscaeB0A8bdq0iWwrKyuz8YwZM/LRnWrFCgQAAAAAABDEAwQAAAAAABBU0CkMCxcudI7HjBmT83OOHz8+1fv27dtnY9+SzgULFjjHS5cujXzt22+/naovQCE5++yzbXzYYYc5bR9++KGN33rrrbz1Cagtnn32WRtPmTLFaSsuLs75+UtLS228evVqp+2SSy6xsU4JBJBbmUzmgDGAdEaMGBHZtmnTJhtXVFTkozvVihUIAAAAAAAgiAcIAAAAAAAgiAcIAAAAAAAgqKD3QBg7dqxzfO2119q4Xr16sT/nuOOOs3GS8osPPvigc7xhw4bI186bN8/Ga9asiX0OoLZp3Lixczxy5MjI186dO9fG+/fvz1mfgNpq48aNNp44caLTdtZZZ9n4qquuysn5ZYnhe++9NyfnAJBcw4YNI9t2796dx54ANZP+rXnMMcdEvnbPnj023rt3b876VChYgQAAAAAAAIJ4gAAAAAAAAIIKOoVBmzZt2kF/xqRJk7LQEwBR9NKt7du321iXMZ0xY0Ze+gQcCnQpVHn86quvOm2yxGJJSYnTJsfp/fff77QVFRU5x6tWrUrXWQA5NXnyZBuXl5c7bbfeemu+uwPUOFVVVc7x0qVLbdyrVy+nbd26dXnpU6FgBQIAAAAAAAjiAQIAAAAAAAjiAQIAAAAAAAiqUXsgACh8eg+EIUOGVFNPAPy/l19+2XsMoHb54IMPbDx9+nSnbdGiRfnuDlDj6PLiU6dOtXEmk3Hali1blpc+FQpWIAAAAAAAgCAeIAAAAAAAgKAivQTD++KiovgvRq4ty2QyA6u7EygMjM3CkclkisKvwqGAcVlQmDNhMTYLCmMTFmOzoESOTVYgAAAAAACAIB4gAAAAAACAIB4gAAAAAACAIB4gAAAAAACAIB4gAAAAAACAIB4gAAAAAACAIB4gAAAAAACAIB4gAAAAAACAIB4gAAAAAACAIB4gAAAAAACAoLoJX19mjNmYi44gsU7V3QEUFMZmYWBcQmJcFg7GJiTGZuFgbEJibBaOyLFZlMlk8tkRAAAAAABQA5HCAAAAAAAAgniAAAAAAAAAgniAAAAAAAAAgniAAAAAAAAAgniAAAAAAAAAgniAAAAAAAAAgniAAAAAAAAAgniAAAAAAAAAgniAAAAAAAAAgniAAAAAAAAAgniAAAAAAAAAgniAAAAAAAAAgniAAAAAAAAAgniAAAAAAAAAgniAAAAAAAAAgniAAAAAAAAAgniAAAAAAAAAguomeXGdOnUyder895lDJpPJeofS8vWlqKgo1ut87zuYz8kG3Zf9+/eXZTKZ4rx2AgWrqKioYMdmXPoaryl/g/x3r6qqMlVVVUWel+MQoufMqqqqWO/TY0GqKeOiusl/d2OYM+Eq5PvZ2k6PzX379jE2YTE2q0+S35pJHyCYFi1a2ONvvvkm8qTyP3iSmyHfa303X74LTF6I+/fv937mYYcddsD3GWNM/fr1bbxv377Y5/f9W8T9t2nQoIHTtnXr1o2Rb8Qhp06dOqZp06b2WI5NfR3La163Sfn+0vb105jvjl3JN47k5/q+p5J8F0lybFZWVsZ6Dw4NvnHpuxYLaVyGzh/3wXrae4S09JxZXl7OnAmrTp06pmXLlvbYNzblXCTvETV9/Wfjf2yF5sW4kjyg9/UtG2NVj82ysjLGJizfb83qvp9N+3A/7fjT4122+b6n0o7TJL81SWEAAAAAAABBPEAAAAAAAABBiVIYMpmM+fbbb+1x2hyVuEu3dFvcpci+pc/16tWL/Ez9Ob7laNla1uX7++vW/e9/HpZGwyeTyZi9e/fa47hj03cd52NPgiT7iuixK8mUoiR/b1RfQmRf5Nj0pVng0FNVVZVqzszW/JJ2KXKSZdq+a9739+YibYE5E3EluZ+NO46SpKiG+pbmfHE/M8l7s7UXGGMTcSW5n017HR9M36I+M0kKRdrUP9/fkfZvjLqfDWEFAgAAAAAACOIBAgAAAAAACEqUwmCMu9TClxoQd0mGXvLha/Mt65JLLn2pB40bN/b2Uy7f0H+T/HuTLOtKu1RFpmLI5V/GuLuSAsa414uMk4xNn1wsOfaNDb2M2jf+GjZsaGO5LFW/T48jKcnSuKjvvrQ7ZKP2ysacKSUZh2mrk8ixt3v3bqdNjyH5Xl2dyLekM+5u1kmqN/jmTN03INtj0ydJBSB5rK/jqD4f6By+8SffmyRdWPLN0b7z6X/fPXv2RL4Ph6Zc38+mlYv7YE2OeT2m0lY4lA5QqtHG+t/X91uTFQgAAAAAACCIBwgAAAAAACCIBwgAAAAAACAo8R4IMndC5mkkyf315Wb4chjluU8++WSn7cwzz7Rxt27dnLYOHTrYuGnTpk7bqlWrnOO77rrLxsuWLXPa8p2/Kj/Tl8sGGBM9Nn35lbne10Dz9UXneunvlEaNGtm4ZcuWTpvcu0TvgSDzNH052knGWK7/DVF7pJkz0+5zoMeXPIdv7NWvX99pk2OxWbNmkW3GuDmSel6U509bfipJjitzJpLI9tj0Xau+/Qr0+JPzlO5LVJ+NMU7pO03vVxD3O8Y3L/v6lmTvEkArlPtZX7/09R+3/Kox7t+kx6a8h037N/n2ENTSzpvMsAAAAAAAIIgHCAAAAAAAIChxCkO26eVRTZo0sbFeSnHTTTfZeOLEiU6bLAPjK9Wmy8X07dvXOZ4+fbqNf/rTnzpt//rXv2ysl67IvvqW2Pj4lnwB2RK3rGg++ErA6WWdHTt2tPGTTz7ptM2cOdPGjz76qNMmvw/0OeIu62I5JrItSVm3uO/zlRfWc5ZMN9BpP3/4wx9sPHr0aKettLTUOf7JT35i488//9xpk0szfcvCfXNmkvKq1f19htoh7dj0fY6vxOLXX3/ttMm5To83vdw5qp+h88t0B53aK+/LdVqEHMd6jvb1JapfwMFIez+bdh7xzbdyTIfKBstxpX+z+sooyzHnmzeTpBdFfUYIKxAAAAAAAEAQDxAAAAAAAEAQDxAAAAAAAEBQteyBIPNEdH6VzAX785//7LTJUo36fXJvA7lXgTHGrFy50sZHH3200zZgwADnuH379jYeMWKE0/bvf//bxjpPROa76Bw18jJxKEmSh+kbGw0aNHCOS0pKbKxLtTZs2NDGevz5cs18OeJxy84xvpENca8pXzk4fX37yjPJ8otjxoxx2saOHWtjuS+RMca0adPGOR4yZIiNH3roIadN51ZLvn2DpGzlowO5EDefWF+rcg+SUaNGOW0TJkyw8S233OK0ffXVVzYO5VnLdj3+5fmLi4udNjln6n3D5Pv0+X1zvW+uBfIt7t5BacsI69+ozZs3d47HjRtn41/+8pdO2xtvvGFjufef5isjmXafEfZAAAAAAAAAWcUDBAAAAAAAEJSXFAa9JEIuwdTLqmRKgVziYYxbzmLt2rVO29VXX21jucTLGGN27Nhh486dOzttuuRby5YtbayXQsvlWrkoJcVyTByMfJZGyloZGDH+GzVqFNlmjDGDBw+2cVlZmdP2xBNP2FguzTbGXdatl3/LMa7Px3hEPsW93vS8JK9v/RlyiaO+9uVceN111zltcizqEo87d+50jmX6kE6hkGNR91v2Ry/FlK9lHKKQ+dKE5Dypx1Hjxo1tfMYZZzhtI0eOtPENN9wQeT5fypLmKzknS7EaY0yfPn1sPHnyZKdNjmlfuqJvPqWMI0IK9RrxXeOSvp/V6XxXXHGFjXv27Om0yTShO++802mTKUW+9D4938o5NklpZB9WIAAAAAAAgCAeIAAAAAAAgCAeIAAAAAAAgKCs7YGQJCdavtaXJ7Jt2zanbePGjTbWZS+2bt1q44qKCqdN5qnoElS6RJVUXl7uHMucTZmjYoz7NyYpB+d7HbmfqA18Y0PmcOo2Xcbx+9//vo2ffvppp62ystLGemzKcZutvRsYm0gjbukoX5kz/T5fbmP9+vVt/MMf/tBpk7nVem8gOffJPQ6M+e74kiUfDz/8cKftscces/GWLVucNjkuZT91mw9zJrIl7dj0lWqU9556PpNj7IQTTnDaNmzYYGO5h1eoLz56TMm9TFq1auW0DRo0yMb6nlnuMeb7twBqgyRzjCzdqPcgGD58uHN8xBFH2Fj/Zl23bp2N9Z5Dsj/6HL577VzsQcIKBAAAAAAAEMQDBAAAAAAAEJSXMo661IVcdqFLrq1YscLG/fv3d9rk0snt27c7bXK5hl4OKUsz3nrrrU5bhw4dnGP5uR9++KHTJpeg6SUgvqUrcZd1sfwLtZEcK77l1/p7QpeWKi4utvFf//rXyPPJMjfGuGkSemxG9dMYxiOyL206m+99cg7V6QXt2rWz8fTp0522Tp06HfAzjHFLzMm5zZjvpjT07t3bxieeeKLTNnr0aBvrUpHvvvtu5GfqZZtS3FJ1jF8kkXZs+kq5+dLnSkpKbHz00Uc7bbNmzbKxLB+u6TZf6US9pFm+VpdFlt8juShZXqgl+oAQOW58aQK67YILLnCOmzVrFvnaZ555xsa+0uPVPcexAgEAAAAAAATxAAEAAAAAAATxAAEAAAAAAATlZQ8EX96zzknetWtXrDaZ12yMm8Op8yllyUddrkrnWi5fvtzG69evd9p8udy+PDjgUKLHghzvvnGj3zdx4kTn+Ntvv7XxmjVrnDaZC+bb5yCt6s41Q+2TrWtKjhv9mVOmTLGxLrEoyyTLPQ+McedQnYMp52Fj3LlX53J+73vfs/Htt9/utMkccF2yWe43pD9Tju+45R6BJHylx330tSqP5Z4jxhhzxx132Fjfa86YMcPGeg8See/r2/PAGLffvnvmI488MvJz9D4Lvn0d5N/rK2fOfIpCkmS8y+tazz/yWJYdN8aYPn36RJ5j48aNTtvrr79uY72vka/0eb73FuFXLwAAAAAACOIBAgAAAAAACMpLCkPcskv6tfp9cimHXjoil2B26dLFaRs5cqSN9fLmHTt2OMd33XWXjSsqKpw2XxlHX3oDy7VQ2yRZ8iWXWepxK9/XqlUrp23gwIHOsVzmpZd1ys/RS77kEkxfekXa7ykg23zzi7725Zw2fvx4p23YsGE2lilAxrjljvW4kON04cKFTttDDz3kHMt0h3POOcdpO//8822s5+XJkyfbWJat03319c33vUN6A3JBX4/yGvQtab7nnnucNplOe/HFFzttMrVWpx7IYz0P+c6v+33UUUfZ+PTTT3fa5L2u/r7x3YfL1/rSK5g/Uch8KbGyTV/jcmzqso2NGjVyjuVYee+995w2nSYoyTHnS2HIxz0rKxAAAAAAAEAQDxAAAAAAAEAQDxAAAAAAAEBQXvZA8PHlcPlKxOg2mc954403Om1du3a1sd7zQOdzrlixwsa6tJUvX5oSNTiUxc1v1DmTMofslFNOcdp07uVHH31k4z179kR+jj6/r00e+/KpGdPIJ991qvMumzdvbmOdSy3nMJnXbIyb21lWVua0TZs2zcZPPvmk0ybLvxnjzr0rV6502mTpKr2nidwD4euvv3baHn/8cRvr74y4e5Xku6QVap6oayTJXODbA+HMM8+08fDhw522JUuW2Pif//yn0+YrRey7D9X7Jcj+6L7JEq9t27Z12mROti8fW38X+cqZx51rgVxIMqblsW+fAd0mr/8BAwY4bfp+Vo7HZ555xmnbvXt3ZL99e6Dk+3coKxAAAAAAAEAQDxAAAAAAAEBQwZVxlMsz9PIQX0maa665xsb9+vVz2uTyyNdff91pmzlzpnMszxl3OVa2UCoOhcS35Mu3rMs3bmTJN/3akpIS7znmzZtnY12STn5v+Mps+VDGEdUp7nWqlzc3a9bMxh06dHDamjZtamO9hPLtt9+28eWXX+60bdmyxcZ6WXSTJk2cY1/6kkxF6NGjh9PWsWNHG1977bVO23PPPWdjnXYo/379byG/MyjjiCTiLv/1pcjp+e2yyy6zsSwnbIwxjzzyiI31fBZ3ftEli/X7ZNqSvi+eMGGCjXVK4AMPPGBjWVLSGH/J5GzMtUB1893D+n4jdu/e3cbHHnus06a/Gz7++GMbv/vuu06bHFe+suS++S/JGEs7HlmBAAAAAAAAgniAAAAAAAAAgniAAAAAAAAAgqplDwRfqSWZw6HLRcnX6nyu8ePH21iWlTLGmNLSUhvfdNNNTpvOC5U5Lbotbo6czouJW+KuuktyAHH59gTQexfIPC2dl9yiRQsb67I3mzZtco4XLVpkY52X7St7FdXPEEpNIZd8Y8h37elcaplb2bJlS6dNjov58+c7bXLfgcrKSqfNV/pUlpjS/dGvffjhh208btw4p03O4bqM3AknnGDjF154wWmTed3630Ly5bECPr6x6buu5J4jxhgzePBgG+v5TJduk+R17SvNqOc9fe8rP6d///5Om9w75YsvvnDa3njjDRvrv1f2R/87+b63uJ9FofL9ZvN9F+j72REjRthY7xWk5005r+k2ue+Bvp+O6ouWj7LkzLAAAAAAACCIBwgAAAAAACAoLykMSZY5yaUVcqmiMe7SqalTpzptbdq0sbEuifPoo4/aeOvWrd6+JklNkOQyE73kJO7SVN+/E0u+UMjk2EiyNFsuay4uLnba5s6d6xzLcqy+1CfNlzIVN6WIdAakUVRUFPvaka/zlUnVbTJtQS+blGmAN998s9NWXl4e2Re5FFqXeEuSXtG8eXMby3QlY9zxpdMVZQmshQsXRp5fj1/GLOLyjU3fvKCXLctrXqYFGDRF3Z4AAA63SURBVOPewy5fvtxpk+NK3+tKvlKNemzqtFv5XdGrV6/IttWrVzttu3btsrG+75XHSUqlcg+LmsI3x8jxrr8/hg4damOdXqTnOD2vSXKM+e5ttbS/NSnjCAAAAAAAcoYHCAAAAAAAIIgHCAAAAAAAICgveyBocfPLdEma4cOH27h3795O286dO2381VdfOW1PPPGEjXVJHJ2zKfNNkuRXxt3XIW2pRkpSoZD4yt4kMWbMGBvrXM+nn37aOZY5ZHrc6vdK7CWCQpH2+14e65JPJ554oo31nLlx40Yb6/1/5FwrS0HqNj1nJilr5dvjRM7Z2qeffmpjPbblHO37HkqSn41DTyaTiT0f+O7h5PWp99/avHmzjTt06OC0yX27tmzZ4rTJPRH0eJPn0N8Fei+FU0891cayNKq2bNky51iOMX1+uc+C/reIe5/KPIx8S/LbK+7crOe0nj17HvDzjfluGVd53Lhx48hz+PY18f1N+cCvUgAAAAAAEMQDBAAAAAAAEMQDBAAAAAAAEJS1PRB8OSO+/QL0+2S+pc69/PWvf21jWV9af86CBQucNlk/Xtfi1LU649az99XmjFtbPsn52AMB+ZYkvypu7lXbtm2dY5mX+fnnnztt77//vnMsx4DO9Y56nTH+/FWgECXZH+G0006zsd5XoFGjRjZu0qSJ01ZRUWFjPZ/JOvDyM4z57hwq+zNhwgSn7frrr7dxixYtnDa5j8nSpUudtkWLFkWeT+Z5630OZF/03A7kgrzO9P5bb7/9to0vuugip+2hhx6y8V/+8henbe3atTaWeyXo406dOjltp5xyinPcr1+/A/bTGHfsfPzxx06bzLv27cfiu2dN8psAyLe0v6/ktTts2DCnTd7f6v1QPvjgA+e4srLygJ9pjDs36rlZvra6xx+/SgEAAAAAQBAPEAAAAAAAQFBeyjgmKYcol2v8/Oc/d9r69u17wNcZY8zzzz9v49mzZzttcgmkLgmlS2T4+u1bHimXg+m++ZbKyNfqvsl/G0pSobrFXR6l2+RY0UssZduSJUucth07djjHcumyLuMYNzUhbrlVINd8yw99y+91W+fOnSPb5LzRqlUrp02WmNPLLeX48qUQGGPMhRdeaOPrrrvOaWvatKmN9fiS57z77rudNplCoUtM+tIH07wOMCb9HCLHhx4bv/vd72ysS77FLbGoS7zJsaHLOOo0wD179thYp/3KMf7ZZ585bTJ9WN97+u7fpbTLq4Fc8F1zvjQB3/tGjhzpHMvfk/oedd68eZGv1WNFzuPZKj+ZC6xAAAAAAAAAQTxAAAAAAAAAQTxAAAAAAAAAQXnZAyFJrqfcB2DSpEmRn6lztmSuWVlZmdMmcyh1XoouUSXzvXTffDmV8rX6dXLfA93my3WRpep0jiqQa77cK1+pRD1uZNuPf/xjp01e459++qnTps8hx66vTYubswnkQtQ158tf9O15o98nr309T2zZssXGek8ROfb0eJJtPXv2dNrGjh3rHF966aU21vnaMj9cl2WeO3eujf/+9787bb5SVXHHMGMdIVE5w757Vl++st7Havv27TbW97O9evWycZcuXZy2o446ysb6u2D58uU23rp1q9Omx/9tt91m47PPPjuybzI2xr1P9c31aUsmMzaRC0muK98cI+n72ZYtW9p40KBBTpuc//SeXrosufxcXZZc7o/gu5+u7r1EWIEAAAAAAACCeIAAAAAAAACC8pLCoPnKUMglIO3bt3fa5FLNyspKp00uJdFtTZo0sbFeYqZfK5eA6aVjcrmWXrolP7dr166Rfevdu7fTJktr6SUuTz/9tI310tCdO3caINvilojxpen40gl0uSq5VGv9+vWR59Pn0JKUkwLyKWqZYZJSqPLa121ffPGFjfXcI0s8XnnllU7b2rVrbXzWWWc5bTJtIbRMUs6TssScMe68pVMLZelGfQ6ZdqiXZcddesq4R7b45kU5F+o0HXnvqe8nV61aZWOZlhAiSzM2a9Ysss0YYz744AMbl5SUOG1y7tXjVn7f+NKp0pZxBPItSVqSbNPzz8CBA23cpk0bp02OI122UZdcjTvGfKq7LDkrEAAAAAAAQBAPEAAAAAAAQBAPEAAAAAAAQFDO9kCQuRm+8oeazCHZtm2b0yb3ROjevbvTNn36dBs3aNDAadNlMCSdd/3xxx/bWOesdOzY0cY9evRw2po3b25jmfdmjJtrpvsm88VPOukkp620tNTGOkduw4YNBjhYacve+PZH0CVpjj/+eBvrHG25B4ku46jzwuTnyjGl+6aRe4lClCQn05f3L0sgDh48OPJ9559/vtMmczDlXjzGuGXdfPudGOOOYT2/yXH68MMPO22yBF2ScnC+vVBkXxn3yAU9/uQ1p8eKnMP0fCY/R+/N5bv+W7duHdmmPyftvkE+ccvIMf5QSHzXY2iOk4477rjItoqKChsvXrzY2x/5u9T33aAVUllyViAAAAAAAIAgHiAAAAAAAICgrKUwZGsptEwbWLJkidM2efJkG3/zzTdOm17SLMnlIbqfXbp0cY67desW+Tm+v1GmIuzYscNpk+kGupSVTKFYunSp0/bGG2/YuGXLlpHnBnLBt4xLpwXJcazLOF544YU21kss161bZ+PPPvvMadMlsXzLk31l7nx830VxsVQTcWXjWtElfR944AEbDx8+3GmTyy31HCmPy8vLnTZfqTj9N8jvgk8++cRpu+eee2z8t7/9zWmT5bH094mcs31l83KxRBvQfPOE7xqUr437OmPc8eC7/kPXuPyu0Of39Ud+NyR5X1zMmci3JCVH5bG+n/X9Rvzqq69srH/r6dTebNyzJnldLsYcKxAAAAAAAEAQDxAAAAAAAEAQDxAAAAAAAEBQzso4Sr78El0+Q7bdeOONTttrr71m406dOjltck+Etm3bOm0yZ0WWlDPGLQ1pjJuHrXOy5V4Ga9euddpkCTpdGlKW9tD7I8i/X+d8y2OZLwpUN18eqL5WTznllMj3vfLKKzaWJVyN+e53g698DfsXoBBlMpnIayztvkF6fMlyx1OmTHHaLrvsMhsPHTrUaZN7G+j9EWSb7v/mzZud4yeeeMLGM2bMcNrkXgqaLPmoy1jFzbOmjByyJW7pNH1dyffp6zgt37Urz6HzqvX527VrF9km75n1HiTyc32lKdlnBLWd3rere/fuNtbz1JdffmnjnTt3xj5HkvvZuPNaNsq0hrACAQAAAAAABPEAAQAAAAAABFV7CoNeHiJVVlY6xy+++KKN9TILuazKt/RZa9WqlXMsy0jqfsvP1cvBfGWn5N/oK4mlP1MuI9NltoBs8C3HDL1WkmOjYcOGTtuKFStsrJc/33///ZGfr8exTOnxpT7lG8s4kW2+saCXLcvXfvTRR07bFVdcYeNhw4Y5beeee66NdTnjr7/+2saLFy922ubOnescl5aW2ljPYTJNQZfD8i2F9pW/IzUB+ZbrVBn9GXFTJjR9P921a9fINpl6pJdby+8bnd4gz6/Hphzjvvt+xjBywTdWEi3NF9e1Ti1ftWqVjQcNGuS0yXmzSZMmTpseY77S53rMpZF2jCW5n2UFAgAAAAAACOIBAgAAAAAACOIBAgAAAAAACMraHghJ8i185dh8exnIvBSdeyVzRnT+iHytzjXRZRXle5Pkvcn3+cre+PZn0P2W72vevLnTxp4IiMuXX+l7bZJcKHldyzwwY9xScrJ0lH6t3jvB1089/uX5k+zjkHb/Avm+qBjwSTtn6jlM8s0hL7/8stP2+uuv21iPS3kd6xxQPYfJc+pxKUtO+vYG8n1H+fZA8OVZxy0FCWhJ5sy0fHOFL3dbXtf6M3Te9VtvvWXjOXPmOG1yLxOdny3nYl3i1XevG1c2crxxaEryuyzuXOHbg0df43fffbeNGzVq5LQtXLjQxnI/PWP8++b5fuvmY7+QtPewzLAAAAAAACCIBwgAAAAAACAocQpD1PIG3xKQtEuKddkZ37KSuMta9DISvcxRt0tyKad+nzxOsjzLtwQs7fIwIBtL6X1lTH3LmJs2beq07dq1y8Z63MglYHpptm+M+b43kvztccv8+MpGkraAKEVFRVm/PpKUF5bLj/W8JK93XRrSdz59Dnl+33LrJCkFvmXavvsAxiWSiHs/m8tzHajNd/8sr3mdeiRThowxZvr06ZGvlfOtL31Qj9u4f4dvWTZjE0lkI9VU880jvs9YuXKljSdNmuS0yXEUKj8sf0/60iu0tL+tpWzNm6xAAAAAAAAAQTxAAAAAAAAAQTxAAAAAAAAAQQe1B4LMowjle8Tl26/Al5cV9zND+R2+cnC+/RHi7leQJNfFl08GSEVFRc6YkNdqtsamr0Ra2pI4vs/07U+SNvcryWt9f1PU2MxHyR3ULHHnzLilSOOeyxj/3gYyB9p3fYf2JvGdXx7rPRh85Sh93xm+88s25kz46P1J5Pzi2y8krbSfkWS8NW7cOPKc+rtAHicZY77vqbjzOWMTPknuZ33XUtzffknGe+vWrSPb5JwWGlNx9x1IUrbSJ839bAgrEAAAAAAAQBAPEAAAAAAAQFDiFAYp7tLkJOUkslHqxbdUJLTkQ7YnWTriKzGXlvy3kSU/gAOJunZ9JQ/TXuN63Mpj39LkJKlHOmVILjPzpUnkQ9TY1GW0ACnunJl2ia9+X9xUpiRl5HxLSH3fGXo8+5ZUxk3n8L2PORNppb2fzZa496F66bUs22pMsrET9Tm+VIQky8kZm4grk8lEXve++1nfa5P8ZpPHvjGWpNS4fq2vxLJv/svF90/asckKBAAAAAAAEMQDBAAAAAAAEMQDBAAAAAAAEFSUsAxEqTFmY+66gwQ6ZTKZ4uruBAoDY7NgMC5hMS4LCmMTFmOzoDA2YTE2C0rk2Ez0AAEAAAAAAByaSGEAAAAAAABBPEAAAAAAAABBPEAAAAAAAABBPEAAAAAAAABBPEAAAAAAAABBPEAAAAAAAABBPEAAAAAAAABBPEAAAAAAAABBPEAAAAAAAABB/wsUy6av8ZQtPgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "8Zqn66hLz1Xw",
        "outputId": "24370881-4f00-4e2c-9f66-6957189d8632"
      },
      "source": [
        "# @title Generate contrastive explanation with pertinent negative\n",
        "# Explained instance\n",
        "idx = 15\n",
        "X = x_test[idx].reshape((1,) + x_test[idx].shape)\n",
        "plt.imshow(X.reshape(28, 28));"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UurAUqcz6a9",
        "outputId": "29eedfa4-fbeb-496e-909d-b7eef9d88c6c"
      },
      "source": [
        "# @title Model prediction\n",
        "cnn.predict(X).argmax(), cnn.predict(X).max()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 0.9998541)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkJwymiqz_w7"
      },
      "source": [
        "\n",
        "# @title CEM parameters\n",
        "# 'PN' (pertinent negative) or 'PP' (pertinent positive):\n",
        "mode = 'PN'\n",
        "# instance shape\n",
        "shape =(1,) + x_train.shape[1:]\n",
        "# minimum difference needed between the prediction probability\n",
        "# for the perturbed instance on the class predicted by the\n",
        "# original instance and the max probability on the other classes\n",
        "# in order for the first loss term to be minimized:\n",
        "kappa =0.\n",
        "# weight of the L1 loss term:\n",
        "beta = .1\n",
        "# weight of the optional autoencoder loss term:\n",
        "gamma =100\n",
        "# initial weight c of the loss term encouraging to predict a\n",
        "# different class (PN) or the same class (PP) for the perturbed\n",
        "# instance compared to the original instance to be explained:\n",
        "c_init =1.\n",
        "# nb of updates for c:\n",
        "c_steps =10\n",
        "# nb of iterations per value of c:\n",
        "max_iterations =1000\n",
        "# feature range for the perturbed instance:\n",
        "feature_range =(x_train.min(),x_train.max())\n",
        "# gradient clipping:\n",
        "clip =(-1000.,1000.)\n",
        "# initial learning rate:\n",
        "lr =1e-2\n",
        "# a value, float or feature-wise, which can be seen as containing\n",
        "# no info to make a prediction\n",
        "# perturbations towards this value means removing features, and\n",
        "# away means adding features for our MNIST images,\n",
        "# the background (-0.5) is the least informative, so\n",
        "# positive/negative perturbations imply adding/removing features:\n",
        "no_info_val =-1."
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZChXcS7A6dZd"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "gMeWKCgdaMwd",
        "outputId": "6f18c919-bea0-456f-e6c8-395222869823"
      },
      "source": [
        "cem = CEM(cnn,mode,shape,kappa=kappa,beta=beta,feature_range=feature_range,gamma=gamma,ae_model=ae,max_iterations=max_iterations,c_init=c_init=,c_steps=c_steps,learning_rate_init=lr,clip=clip,no_info_val=no_info_val)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-74ec6e474b6e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    cem = CEM(cnn,mode,shape,kappa=kappa,beta=beta,feature_range=feature_range,gamma=gamma,ae_model=ae,max_iterations=max_iterations,c_init=c_init=,c_steps=c_steps,learning_rate_init=lr,clip=clip,no_info_val=no_info_val)\u001b[0m\n\u001b[0m                                                                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "c7x8NMT46nEP",
        "outputId": "b0ff4206-ea26-483e-a61c-037656786dea"
      },
      "source": [
        "shape = (1,) + x_train.shape[1:]\n",
        "mode = 'PN'\n",
        "cem = CEM(cnn, mode, shape, kappa=0., beta=.1,\n",
        "          feature_range=(x_train.min(), x_train.max()),\n",
        "          gamma=100, ae_model=ae, max_iterations=1000,\n",
        "          c_init=1., c_steps=10, learning_rate_init=1e-2,\n",
        "          clip=(-1000.,1000.), no_info_val=-1.)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-1e829c39c65e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mae_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mc_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           clip=(-1000.,1000.), no_info_val=-1.)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/alibi/explainers/cem.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, predict, mode, shape, kappa, beta, feature_range, gamma, ae_model, learning_rate_init, max_iterations, c_init, c_steps, eps, clip, update_num_grad, no_info_val, write_dir, sess)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_model\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Keras or TF model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1114\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n\u001b[0m\u001b[1;32m   1117\u001b[0m                          'graph before calling run().')\n\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The Session graph is empty.  Add operations to the graph before calling run()."
          ]
        }
      ]
    }
  ]
}